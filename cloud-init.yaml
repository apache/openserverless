#cloud-config
apt_update: true
apt_upgrade: true
packages:
  - at

users:
  - name: ubuntu
    uid: 1000
    groups: sudo
    shell: /bin/bash
    sudo: ['ALL=(ALL) NOPASSWD:ALL']

write_files:
  - path: /etc/cloud-init.sh
    permissions: '0755'
    owner: root:root
    content: |
      echo "OPS_CLOUD_INIT_VER=3" >>/etc/environment
      IP="$(ip -o -4 addr | awk '$2 ~/en/ { print $4}' | cut -d/ -f1)"
      # install k3s, direnv, task
      curl -sfL https://get.k3s.io | sh -
      # set home and user
      USR="$(getent passwd 1000 | awk -F: '{print $1}')"
      HOME="/home/$USR"
      # copy authkey if there is a root one
      mkdir -p /home/$USR/.ssh
      if test -e /root/.ssh/authorized_keys
      then cat /root/.ssh/authorized_keys >>/home/$USR/.ssh/authorized_keys
      fi
      # access k3s
      mkdir -p "$HOME/.kube"
      cat /etc/rancher/k3s/k3s.yaml "$HOME/.kube/config" | sed -e 's!server: https://127.0.0.1:!server: https://'$IP':!' >"$HOME/.kube/config"
      echo "export KUBECONFIG=/home/$USR/.kube/config" >>$HOME/.bashrc
      chown -Rvf "$USR" /home/$USR
      #sudo -u $USR bash /etc/install-opsv.sh
      echo "== DONE =="

  - path: /etc/install-opsv.sh
    permissions: '0755'
    owner: root:root
    content: |
        curl -sL bit.ly/get-ops | bash
        # TODO: use the released version not main
        echo "export OPS_BRANCH=main" >> ~/.bashrc
        source ~/.bashrc
        ops -t
        ops -info
        # configure opsv
        ops config slim 
        IP="$(ip -o -4 addr | awk '$2 ~/en/ { print $4}' | cut -d/ -f1)"
        ops config apihost "$IP.nip.io"
        ops setup cluster

  - path: /home/ubuntu/waitready
    permissions: '0755'
    owner: ubuntu:ubuntu
    defer: true
    content: |
      #!/bin/bash
      sudo cloud-init status --wait
      tail -f /tmp/cloud-init.log | while read line
      do echo "$line"
        if [[ "$line" == *"== DONE =="* ]]
        then exit 0
        fi
      done
  
  - path: /home/ubuntu/i-am-a-developer
    permissions: '0755'
    defer: true
    owner: ubuntu:ubuntu
    content: |
      # get openserverless sources
      cd $HOME
      # install task and skywalking-eyes
      sudo snap install task --classic
      sudo snap install go --classic
      go install github.com/apache/skywalking-eyes/cmd/license-eye@latest
      echo "export PATH=\$PATH:\$HOME/go/bin" >> .bashrc
      # install direnv and nix
      curl -sL https://nixos.org/nix/install | sh
      source .profile
      curl -sL https://direnv.net/install.sh | sudo bash
      echo 'eval "$(direnv hook bash)"' >> .bashrc
      source .bashrc
      # setup openserverless
      git clone https://github.com/apache/openserverless.git --recurse-submodules
      cd openserverless 
      bash sync-branch.sh
      bash direnv-init.sh
      # TODO add a .git-hooks directory with hooks
      #git config core.hooksPath .git-hooks

  - path: /home/ubuntu/add-rook
    permissions: '0755'
    defer: true
    owner: ubuntu:ubuntu
    content: |
      #!/bin/bash
      set -e

      ROOK_VERSION="v1.14.6"
      RAW_BASE="https://raw.githubusercontent.com/rook/rook/${ROOK_VERSION}/deploy/examples"

      echo "üì¶ Installing Rook ${ROOK_VERSION}"
      echo "üìÑ Applying CRDs and operator..."
      kubectl apply -f ${RAW_BASE}/crds.yaml
      kubectl apply -f ${RAW_BASE}/common.yaml
      kubectl apply -f ${RAW_BASE}/operator.yaml
      sleep 10

      echo "üîé Checking for yq..."
      if ! command -v yq >/dev/null 2>&1; then
        echo "üì• Installing yq..."
        mkdir -p /home/ubuntu/bin
        curl -sL https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -o /home/ubuntu/bin/yq
        chmod +x /home/ubuntu/bin/yq
        export PATH=/home/ubuntu/bin:$PATH
      else
        echo "‚úÖ yq already installed."
      fi

      echo "üõ†Ô∏è Patching and applying Ceph cluster for single-node setup..."
      curl -sL ${RAW_BASE}/cluster.yaml | \
        yq e '.spec.mon.count = 1 | .spec.mon.allowMultiplePerNode = true' - | \
        kubectl apply -f -
      sleep 30

      echo "üìÑ Applying Ceph client..."
      kubectl apply -f ${RAW_BASE}/ceph-client.yaml

      echo "üîç Waiting for Rook to be Ready..."
      for i in {1..90}; do
        status=$(kubectl -n rook-ceph get cephcluster rook-ceph -o jsonpath='{.status.phase}' 2>/dev/null || echo "notfound")
        echo "‚è≥ Attempt $i: Rook status = $status"
        if [[ "$status" == "Ready" ]]; then
          echo "‚úÖ Rook is healthy!"
          break
        fi
        sleep 15
      done

      if [[ "$status" != "Ready" ]]; then
        echo "‚ùå Timeout waiting for Rook to become healthy."
        exit 1
      fi

      echo "üìÑ Installing VolumeSnapshot CRDs..."
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/v6.3.3/client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/v6.3.3/client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/v6.3.3/client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml

      echo "üßπ Re-creating rook-ceph-block StorageClass..."
      kubectl delete storageclass rook-ceph-block --ignore-not-found=true

      cat <<EOF | kubectl apply -f -
      apiVersion: storage.k8s.io/v1
      kind: StorageClass
      metadata:
        name: rook-ceph-block
        annotations:
          storageclass.kubernetes.io/is-default-class: "true"
      provisioner: rook-ceph.rbd.csi.ceph.com
      allowVolumeExpansion: true
      reclaimPolicy: Delete
      volumeBindingMode: WaitForFirstConsumer
      parameters:
        clusterID: rook-ceph
        pool: replicapool
        imageFormat: "2"
        imageFeatures: layering
        csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
        csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
        csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
        csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
        csi.storage.k8s.io/fstype: ext4
      EOF

      echo "‚úÖ Rook installed and configured with default StorageClass rook-ceph-block."


  - path: /home/ubuntu/add-longhorn
    permissions: '0755'
    defer: true
    owner: ubuntu:ubuntu
    content: |
      #!/bin/bash
      set -e
      LONGHORN_VERSION="v1.4.1"
      
      echo "üì¶ Installing Longhorn ${LONGHORN_VERSION}"
      kubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/${LONGHORN_VERSION}/deploy/longhorn.yaml

      for i in {1..90}; do
        ready=$(kubectl -n longhorn-system get pods -l app=longhorn-manager -o jsonpath='{.items[*].status.containerStatuses[0].ready}' | grep -o true | wc -l)
        total=$(kubectl -n longhorn-system get pods -l app=longhorn-manager --no-headers | wc -l)
        echo "‚è≥ Attempt $i: $ready/$total pods ready"
        [[ "$ready" == "$total" && "$total" -gt 0 ]] && echo "‚úÖ Longhorn Ready" && break
        sleep 15
      done

      echo "üì¶ Trying to set Longhorn as default storage class ..."
      if kubectl get storageclass longhorn >/dev/null 2>&1; then
        kubectl annotate storageclass longhorn storageclass.kubernetes.io/is-default-class=true --overwrite || true
      fi

runcmd:
  - |
    cd /home/ubuntu
    # add z.sh and .aliases
    curl -sL "https://raw.githubusercontent.com/rupa/z/master/z.sh" -o ".z.sh"
    curl -sL https://raw.githubusercontent.com/sciabarracom/openserverless/refs/heads/main/bash_aliases -o ".bash_aliases"
    echo 'source $HOME/.z.sh' >> .bashrc
    chown ubuntu:ubuntu .z.sh .bashrc .bash_aliases 
    echo -e '#!/bin/bash\n/etc/cloud-init.sh 2>&1 >/tmp/cloud-init.log\n' | at now